#!/usr/bin/env python

import sys
import os
import inspect
current_dir = os.path.realpath(os.path.abspath(os.path.dirname(inspect.getfile(inspect.currentframe()))))

## for when config is still in recipes directory:
sys.path.append(current_dir + '/../scripts/')
sys.path.append(current_dir + '/../scripts/processors/')

## for after config is copied to voice.cfg:
sys.path.append(current_dir + '/../../../../scripts/')
sys.path.append(current_dir + '/../../../../scripts/processors/')

from Tokenisers import RegexTokeniser
from Phonetisers import NaivePhonetiser
from FeatureExtractor import WorldExtractor
from FeatureDumper import FeatureDumper
from Aligner import StateAligner
from SKLProcessors import SKLDecisionTreePausePredictor 
from PhraseMaker import PhraseMaker
from AcousticModel import AcousticModelWorld
from NN import NNDurationPredictor, NNAcousticPredictor


import default.const as c







## ----------------------------------------------------------------
## First define a few things used later:

## Some useful Xpaths and regex:--
#CONTENT_NODES = "//token[@token_class='word'] | //token[@token_class='punctuation']"
JUNCTURE_NODES = "//token[@token_class='space'] | //token[@token_class='punctuation']"

LETTER_PATT = '[\p{L}||\p{N}||\p{M}]'
PUNC_PATT = '[\p{C}||\p{P}||\p{S}]'
SPACE_PATT = '\p{Z}'
PUNC_OR_SPACE_PATT = '[\p{Z}||\p{C}||\p{P}||\p{S}]'

## 
speech_coding_config = {'order': 59, 'static_window': '1', 'delta_window': '-0.5 0.0 0.5', 'delta_delta_window': '1.0 -2.0 1.0'}


pause_predictor_features = [        
        ('response', './attribute::has_silence="yes"'), 
        ('token_is_punctuation', './attribute::token_class="punctuation"'),
        ('end_of_sentence', './attribute::token_class="%s"'%(c.TERMINAL)),        
        ('since_start_utterance_in_words', "count(preceding::token[@token_class='word'])"),
        ('till_end_utterance_in_words', "count(following::token[@token_class='word'])")
]     

        # L_vsm_d1 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d1
        # L_vsm_d2 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d2
        # L_vsm_d3 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d3
        # L_vsm_d4 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d4
        # L_vsm_d5 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d5
        # L_vsm_d6 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d6
        # L_vsm_d7 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d7
        # L_vsm_d8 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d8
        # L_vsm_d9 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d9
        # L_vsm_d10 = ./preceding::token[@token_class!='space'][1]/attribute::word_vsm_d10

        # C_vsm_d1 = ./attribute::word_vsm_d1
        # C_vsm_d2 = ./attribute::word_vsm_d2
        # C_vsm_d3 = ./attribute::word_vsm_d3
        # C_vsm_d4 = ./attribute::word_vsm_d4
        # C_vsm_d5 = ./attribute::word_vsm_d5
        # C_vsm_d6 = ./attribute::word_vsm_d6
        # C_vsm_d7 = ./attribute::word_vsm_d7
        # C_vsm_d8 = ./attribute::word_vsm_d8
        # C_vsm_d9 = ./attribute::word_vsm_d9
        # C_vsm_d10 = ./attribute::word_vsm_d10
        
        # R_vsm_d1 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d1
        # R_vsm_d2 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d2
        # R_vsm_d3 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d3
        # R_vsm_d4 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d4
        # R_vsm_d5 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d5
        # R_vsm_d6 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d6
        # R_vsm_d7 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d7
        # R_vsm_d8 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d8
        # R_vsm_d9 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d9
        # R_vsm_d10 = ./following::token[@token_class!='space'][1]/attribute::word_vsm_d10
        


    
phone_contexts = [
        ## special named features:
        ('htk_monophone', './attribute::pronunciation'),
        ('start_time', './attribute::start'),
        ('end_time', './attribute::end'),

        ## normal features:
        ('ll_segment', 'preceding::segment[2]/attribute::pronunciation'),
        ('l_segment', 'preceding::segment[1]/attribute::pronunciation'),
        ('c_segment', './attribute::pronunciation'),
        ('r_segment', 'following::segment[1]/attribute::pronunciation'),
        ('rr_segment', 'following::segment[2]/attribute::pronunciation'),

        ## letter VSM features
        # ('l_segment_vsm_d1 =      preceding::segment[1]/attribute::segment_vsm_d1
        # ('l_segment_vsm_d2 =      preceding::segment[1]/attribute::segment_vsm_d2
        # ('l_segment_vsm_d3 =      preceding::segment[1]/attribute::segment_vsm_d3
        # l_segment_vsm_d4 =      preceding::segment[1]/attribute::segment_vsm_d4
        # l_segment_vsm_d5 =      preceding::segment[1]/attribute::segment_vsm_d5
        # c_segment_vsm_d1 =                          ./attribute::segment_vsm_d1
        # c_segment_vsm_d2 =                          ./attribute::segment_vsm_d2
        # c_segment_vsm_d3 =                          ./attribute::segment_vsm_d3
        # c_segment_vsm_d4 =                          ./attribute::segment_vsm_d4
        # c_segment_vsm_d5 =                          ./attribute::segment_vsm_d5
        # r_segment_vsm_d1 =      following::segment[1]/attribute::segment_vsm_d1
        # r_segment_vsm_d2 =      following::segment[1]/attribute::segment_vsm_d2
        # r_segment_vsm_d3 =      following::segment[1]/attribute::segment_vsm_d3
        # r_segment_vsm_d4 =      following::segment[1]/attribute::segment_vsm_d4
        # r_segment_vsm_d5 =      following::segment[1]/attribute::segment_vsm_d5
        
        
        ## WORD LEVEL:
        ('length_left_word', "count(ancestor::token/preceding::token[@token_class='word'][1]/descendant::segment)"),
        ('length_current_word', 'count(ancestor::token/descendant::segment)'),
        ('length_right_word', "count(ancestor::token/following::token[@token_class='word'][1]/descendant::segment)"),

        ('since_beginning_of_word', 'count(./preceding-sibling::segment)'),
        ('till_end_of_word', 'count(./following-sibling::segment)'),

        ## phrase LEVEL:
        ('length_l_phrase_in_words', "count(ancestor::phrase/preceding::phrase[1]/descendant::token[@token_class='word'])"),
        ('length_c_phrase_in_words', "count(ancestor::phrase/descendant::token[@token_class='word'])"),
        ('length_r_phrase_in_words', "count(ancestor::phrase/following::phrase[1]/descendant::token[@token_class='word'])"),

        ('length_l_phrase_in_segments', 'count(ancestor::phrase/preceding::phrase[1]/descendant::segment)'),
        ('length_c_phrase_in_segments', 'count(ancestor::phrase/descendant::segment)'),
        ('length_r_phrase_in_segments', 'count(ancestor::phrase/following::phrase[1]/descendant::segment)'),

        ('since_phrase_start_in_segs', 'count(ancestor::token/preceding-sibling::token/descendant::segment)'),
        ('till_phrase_end_in_segs', 'count(ancestor::token/following-sibling::token/descendant::segment)'),

        ('since_phrase_start_in_words', "count(ancestor::token/preceding-sibling::token[@token_class='word'])"),
        ('till_phrase_end_in_words', "count(ancestor::token/following-sibling::token[@token_class='word'])"),

        ## UTT LEVEL:
        ('since_start_utterance_in_segments', 'count(preceding::segment)'),
        ('since_start_utterance_in_words', "count(preceding::token[@token_class='word'])"),
        ('since_start_utterance_in_phrases', 'count(preceding::phrase)'),

        ('till_end_utterance_in_segments', 'count(following::segment)'),
        ('till_end_utterance_in_words', "count(following::token[@token_class='word'])"),
        ('till_end_utterance_in_phrases', 'count(following::phrase)'),

        ('length_utterance_in_segments', 'count(ancestor::utt/descendant::segment)'),
        ('length_utterance_in_words', "count(ancestor::utt/descendant::token[@token_class='word'])"),
        ('length_utterance_in_phrases', 'count(ancestor::utt/descendant::phrase)')
]




state_contexts = [

    ## special named features:
    ("start_time", "./attribute::start"),
    ("end_time", "./attribute::end"),
    ("htk_state", "count(./preceding-sibling::state) + 1"),
    ("htk_monophone", "./ancestor::segment/attribute::pronunciation"),

    ("ll_segment", "./ancestor::segment/preceding::segment[2]/attribute::pronunciation"),
    ("l_segment", "./ancestor::segment/preceding::segment[1]/attribute::pronunciation"),
    ("c_segment", "./ancestor::segment/attribute::pronunciation"),
    ("r_segment", "./ancestor::segment/following::segment[1]/attribute::pronunciation"),
    ("rr_segment", "./ancestor::segment/following::segment[2]/attribute::pronunciation"),

    ## letter VSM features
    # ("l_segment_vsm_d1", "./ancestor::segment/preceding::segment[1]/attribute::segment_vsm_d1"),
    # ("l_segment_vsm_d2", "./ancestor::segment/preceding::segment[1]/attribute::segment_vsm_d2"),
    # ("l_segment_vsm_d3", "./ancestor::segment/preceding::segment[1]/attribute::segment_vsm_d3"),
    # ("l_segment_vsm_d4", "./ancestor::segment/preceding::segment[1]/attribute::segment_vsm_d4"),
    # ("l_segment_vsm_d5", "./ancestor::segment/preceding::segment[1]/attribute::segment_vsm_d5"),
    # ("c_segment_vsm_d1", "./ancestor::segment/attribute::segment_vsm_d1"),
    # ("c_segment_vsm_d2", "./ancestor::segment/attribute::segment_vsm_d2"),
    # ("c_segment_vsm_d3", "./ancestor::segment/attribute::segment_vsm_d3"),
    # ("c_segment_vsm_d4", "./ancestor::segment/attribute::segment_vsm_d4"),
    # ("c_segment_vsm_d5", "./ancestor::segment/attribute::segment_vsm_d5"),
    # ("r_segment_vsm_d1", "./ancestor::segment/following::segment[1]/attribute::segment_vsm_d1"),
    # ("r_segment_vsm_d2", "./ancestor::segment/following::segment[1]/attribute::segment_vsm_d2"),
    # ("r_segment_vsm_d3", "./ancestor::segment/following::segment[1]/attribute::segment_vsm_d3"),
    # ("r_segment_vsm_d4", "./ancestor::segment/following::segment[1]/attribute::segment_vsm_d4"),
    # ("r_segment_vsm_d5", "./ancestor::segment/following::segment[1]/attribute::segment_vsm_d5"),

    ## WORD LEVEL:
    ("length_left_word", "count(ancestor::token/preceding::token[@token_class='word'][1]/descendant::segment)"),
    ("length_current_word", "count(ancestor::token/descendant::segment)"),
    ("length_right_word", "count(ancestor::token/following::token[@token_class='word'][1]/descendant::segment)"),
    ("since_beginning_of_word", "count_Xs_since_start_Y('segment', 'token')"),
    ("till_end_of_word", "count_Xs_till_end_Y('segment', 'token')"),

    ## phrase LEVEL:
    ("length_l_phrase_in_words", "count(ancestor::phrase/preceding::phrase[1]/descendant::token[@token_class='word'])"),
    ("length_c_phrase_in_words", "count(ancestor::phrase/descendant::token[@token_class='word'])"),
    ("length_r_phrase_in_words", "count(ancestor::phrase/following::phrase[1]/descendant::token[@token_class='word'])"),

    ("length_l_phrase_in_segments", "count(ancestor::phrase/preceding::phrase[1]/descendant::segment)"),
    ("length_c_phrase_in_segments", "count(ancestor::phrase/descendant::segment)"),
    ("length_r_phrase_in_segments", "count(ancestor::phrase/following::phrase[1]/descendant::segment)"),

    ("since_phrase_start_in_segs", "count_Xs_since_start_Y('segment', 'phrase')"),
    ("till_phrase_end_in_segs", "count_Xs_till_end_Y('segment', 'phrase')"),

    ("since_phrase_start_in_words", "count_Xs_since_start_Y('token[@token_class=\"word\"]', 'phrase')"),
    ("till_phrase_end_in_words", "count_Xs_till_end_Y('token[@token_class=\"word\"]', 'phrase')"),

    ## SENTENCE (UTT) LEVEL
    ("since_start_sentence_in_segments", "count_Xs_since_start_Y('segment', 'utt')"),
    ("since_start_sentence_in_words", "count_Xs_since_start_Y('token[@token_class=\"word\"]', 'utt')"),
    ("since_start_sentence_in_phrases", "count_Xs_since_start_Y('phrase', 'utt')"),
    ("till_end_sentence_in_segments", "count_Xs_till_end_Y('segment', 'utt')"),
    ("till_end_sentence_in_words", "count_Xs_till_end_Y('token[@token_class=\"word\"]', 'utt')"),
    ("till_end_sentence_in_phrases", "count_Xs_till_end_Y('phrase', 'utt')"),
    ("length_sentence_in_segments", "count(ancestor::utt/descendant::segment)"),
    ("length_sentence_in_words", "count(ancestor::utt/descendant::token[@token_class='word'])"),
    ("length_sentence_in_phrases", "count(ancestor::utt/descendant::phrase)")
]

duration_data_contexts = [('state_%s_nframes'%(i), '(./state[%s]/attribute::end - ./state[%s]/attribute::start) div 5'%(i,i)) for i in [1,2,3,4,5]]


## ----------------------------------------------------------------
## Now, a number of utterance processors are defined:--

tokeniser = RegexTokeniser('word_splitter', target_nodes='//utt', split_attribute='text', \
                            child_node_type='token', add_terminal_tokens=True, \
                            class_patterns = [('space', '\A'+SPACE_PATT+'+\Z'), ('punctuation', '\A'+PUNC_OR_SPACE_PATT+'+\Z')], \
                            split_pattern='('+SPACE_PATT+'*'+PUNC_PATT+'*'+SPACE_PATT+'+|'+SPACE_PATT+'*'+PUNC_PATT+'+\Z)'  )
                                                    ## modified to handle word-internal hyphens

# phonetiser = RegexTokeniser('letter_splitter', target_nodes="//token[@token_class='word']", split_attribute='text', \
#                             child_node_type='segment', add_terminal_tokens=False, add_safetext=True, \
#                             split_pattern = '(.)', add_token_classes=False )

phonetiser = NaivePhonetiser('segment_adder', target_nodes="//token", target_attribute='text', child_node_type='segment', \
                            class_attribute='token_class', output_attribute='pronunciation', word_classes = ['word'], \
                            probable_pause_classes = ['punctuation', c.TERMINAL], possible_pause_classes=['space'])

speech_feature_extractor = WorldExtractor('acoustic_feature_extractor', input_filetype='wav', output_filetype='cmp', \
                            coding_config=speech_coding_config, sample_rate=48000, alpha=0.77, mcep_order=59)

align_label_dumper = FeatureDumper(target_nodes='//segment', output_filetype='align_lab', contexts=[('segment', './attribute::pronunciation')])
 
aligner = StateAligner(target_nodes='//segment', target_attribute='pronunciation', input_label_filetype='align_lab', acoustic_feature_filetype='cmp', \
                    output_label_filetype='time_lab', silence_tag='has_silence', min_silence_duration=50, viterbi_beam_width='1000 100000 1000000', \
                    acoustic_subrecipe='standard_alignment')

pause_predictor = SKLDecisionTreePausePredictor(processor_name='pause_predictor', target_nodes=JUNCTURE_NODES, output_attribute='silence_predicted', contexts=pause_predictor_features)
        
phrase_adder = PhraseMaker(node_type_to_regroup='token', parent_node_type='phrase', \
                 attribute_with_silence='pronunciation', silence_symbol='sil')

dur_data_maker = FeatureDumper(processor_name='duration_data_maker', target_nodes='//segment', context_separators='spaces', output_filetype='dur_data', \
                question_file='null', contexts=duration_data_contexts, binary_output=True)

dur_label_maker = FeatureDumper(processor_name='labelmaker', target_nodes='//segment', context_separators='numbers', output_filetype='lab_dur', \
                question_file='questions_dur.hed', question_filter_threshold = 5, contexts=phone_contexts)

duration_predictor = NNDurationPredictor(processor_name='duration_predictor', question_file='questions_dur.hed', target_nodes='//segment')

dnn_label_maker = FeatureDumper(processor_name='dnn_labelmaker', target_nodes='//state', context_separators='numbers', output_filetype='lab_dnn', \
                question_file='questions_dnn.hed', question_filter_threshold=5, contexts=state_contexts)

acoustic_predictor = NNAcousticPredictor(variance_expansion=0.3, sample_rate=48000, alpha=0.77, mcep_order=59, input_label_filetype='lab_dnn')


## -----------------------------------------------------------------
## The processors are grouped for convenience into several 'stages':

text_proc = [tokeniser, phonetiser]
alignment = [align_label_dumper, speech_feature_extractor, aligner, pause_predictor, phrase_adder, dur_data_maker]
pause_prediction = [pause_predictor, phrase_adder] 
speech_generation = [dur_label_maker, duration_predictor, dnn_label_maker, acoustic_predictor]



## ----------------------------------------------------------------
## The final part of the config specifies which stages are run in each of the modes
## "train" and "runtime" (and optionally extra, specialised, modes):

train_stages   = [text_proc, alignment,        speech_generation]

runtime_stages = [text_proc, pause_prediction, speech_generation]

